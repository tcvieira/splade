{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "expired-priority",
   "metadata": {},
   "source": [
    "# Train SPLADE: Sparse Lexical and Expansion Model using MMARCO-pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "becoming-television",
   "metadata": {},
   "source": [
    "This notebook gives a minimal example usage of SPLADE.\n",
    "\n",
    "* code [my github](https://github.com/tcvieira/IA368-DD-012023)\n",
    "* splade forked from  [Naver Labs Splade](https://github.com/naver/splade)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48faff67",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259985df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15c5bcf4",
   "metadata": {},
   "source": [
    "## Checkout my splade fork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3bb6822",
   "metadata": {},
   "source": [
    "# Splade\n",
    "\n",
    "- train\n",
    "> SPLADE_CONFIG_NAME=config_splade_mmarco-pt python -m src.train\n",
    "\n",
    "- index\n",
    "> SPLADE_CONFIG_NAME=config_splade_mmarco-pt python -m src.index\n",
    "\n",
    "- retrieve\n",
    "> SPLADE_CONFIG_NAME=config_splade_mmarco-pt python -m src.retrieve\n",
    "\n",
    "- all\n",
    "> SPLADE_CONFIG_NAME=config_splade_mmarco-pt python -m src.all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1640517",
   "metadata": {},
   "source": [
    "to create Anserini readable files (after training), run \n",
    "\n",
    ">SPLADE_CONFIG_FULLPATH=/path/to/checkpoint/dir/config.yaml python3 -m splade.create_anserini +quantization_factor_document=100 +quantization_factor_query=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b499e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hydra-core in /usr/local/Caskroom/miniforge/base/envs/splade_env/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/Caskroom/miniforge/base/envs/splade_env/lib/python3.9/site-packages (from hydra-core) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/Caskroom/miniforge/base/envs/splade_env/lib/python3.9/site-packages (from hydra-core) (4.9.3)\n",
      "Requirement already satisfied: packaging in /usr/local/Caskroom/miniforge/base/envs/splade_env/lib/python3.9/site-packages (from hydra-core) (23.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/Caskroom/miniforge/base/envs/splade_env/lib/python3.9/site-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hydra-core --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "079a66a3",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b8bbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tcvieira/GitHub/splade-mine/splade/train.py:20: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME)\n",
      "/usr/local/Caskroom/miniforge/base/envs/splade_env/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config_splade_mmarco-pt': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/usr/local/Caskroom/miniforge/base/envs/splade_env/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "config:\n",
      "  lr: 2.0e-05\n",
      "  seed: 123\n",
      "  gradient_accumulation_steps: 1\n",
      "  weight_decay: 0.01\n",
      "  validation_metrics:\n",
      "  - MRR@10\n",
      "  - recall@100\n",
      "  - recall@200\n",
      "  - recall@500\n",
      "  pretrained_no_yamlconfig: false\n",
      "  nb_iterations: 150000\n",
      "  train_batch_size: 16\n",
      "  eval_batch_size: 16\n",
      "  index_retrieve_batch_size: 16\n",
      "  record_frequency: 10000\n",
      "  train_monitoring_freq: 500\n",
      "  warmup_steps: 6000\n",
      "  max_length: 256\n",
      "  fp16: true\n",
      "  matching_type: splade\n",
      "  monitoring_ckpt: MRR@10\n",
      "  tokenizer_type: distilbert-base-uncased\n",
      "  top_k: 1000\n",
      "  eval_metric:\n",
      "  - - mrr_10\n",
      "    - recall\n",
      "  - - ndcg_cut\n",
      "  - - mrr_10\n",
      "    - recall\n",
      "  - - ndcg_cut\n",
      "  - - mrr_10\n",
      "    - recall\n",
      "  threshold: 0\n",
      "  loss: DistilMarginMSE\n",
      "  augment_pair: in_batch_negatives\n",
      "  regularizer:\n",
      "    FLOPS: null\n",
      "    lambda_q: 0.5\n",
      "    lambda_d: 0.4\n",
      "    T: 50000\n",
      "    targeted_rep: rep\n",
      "    reg: FLOPS\n",
      "  checkpoint_dir: experiments/mmarco-pt-v1/checkpoint\n",
      "  index_dir: experiments/mmarco-pt-v1/index\n",
      "  out_dir: experiments/mmarco-pt-v1/out\n",
      "data:\n",
      "  type: triplets\n",
      "  TRAIN_DATA_DIR: data/mmarco-pt/triplets\n",
      "  VALIDATION_SIZE_FOR_LOSS: 60000\n",
      "  VALIDATION_FULL_RANKING:\n",
      "    D_COLLECTION_PATH: data/mmarco-pt/val_collection\n",
      "    Q_COLLECTION_PATH: data/mmarco-pt/val_queries\n",
      "    QREL_PATH: data/mmarco-pt/qrel/qrel.json\n",
      "    TOP_K: 500\n",
      "  COLLECTION_PATH: data/mmarco-pt/full_collection\n",
      "  Q_COLLECTION_PATH:\n",
      "  - data/msmarco/dev_queries\n",
      "  - data/msmarco/TREC_DL_2019/queries_2019\n",
      "  - data/msmarco/TREC_DL_2020/queries_2020\n",
      "  EVAL_QREL_PATH:\n",
      "  - data/msmarco/dev_qrel.json\n",
      "  - data/msmarco/TREC_DL_2019/qrel.json\n",
      "  - data/msmarco/TREC_DL_2019/qrel_binary.json\n",
      "  - data/msmarco/TREC_DL_2020/qrel.json\n",
      "  - data/msmarco/TREC_DL_2020/qrel_binary.json\n",
      "  flops_queries: data/mmarco-pt/all_dev_queries/\n",
      "init_dict:\n",
      "  model_type_or_dir: distilbert-base-uncased\n",
      "  model_type_or_dir_q: null\n",
      "  freeze_d_model: 0\n",
      "  agg: max\n",
      "  fp16: true\n",
      "\n",
      "/usr/local/Caskroom/miniforge/base/envs/splade_env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Error executing job with overrides: ['config.checkpoint_dir=experiments/mmarco-pt-v1/checkpoint', 'config.index_dir=experiments/mmarco-pt-v1/index', 'config.out_dir=experiments/mmarco-pt-v1/out']\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tcvieira/GitHub/splade-mine/splade/train.py\", line 79, in train\n",
      "    temp = {\"loss\": init_regularizer(config[\"regularizer\"][reg][\"reg\"]),\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "!SPLADE_CONFIG_NAME=config_splade_mmarco-pt python3 -m splade.train \\\n",
    "  config.checkpoint_dir=experiments/mmarco-pt-v1/checkpoint \\\n",
    "  config.index_dir=experiments/mmarco-pt-v1/index \\\n",
    "  config.out_dir=experiments/mmarco-pt-v1/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92456b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
